

# üìù R√©ponses pour la section: Pour aller plus loin

## Gestion des donn√©es √† grande √©chelle avec Polars sur GCP

### R√©sum√©

- M√™me si la librairie Polars permet de g√©rer des volumes importants de donn√©es, ils existent d'autres solutions robustes sur GCP √† savoir Dataflow (Apache Beam), Dataproc (PySpark), ou encore Bigquery (depuis dbt ou dataflow) qui sont des solutions manag√©es ou encore serverless.
Cependant pour profiter pleinement des avantages que Polars pr√©sente, il faut provisionner les ressources ad√©quates pour garantir le passage √† l'√©chelle et les calculs en temps r√©els.

La solution pr√©sent√©e consiste √† traiter les 3 types de fichiers dans le m√™me container. Afin de faire √©voluer la solution pour qu'elle puisse prendre en compte un nombre important de fichiers, il convient d'abord de d√©dier √† chaque traitement de fichier une t√¢che √† part qui s'ex√©cute ind√©pendamment des autres taches dans un orchestrateur. Ceci permet de scale la tache lorsqu'il y a un nombre important de fichiers.
Par exemple on peut provisionner des Cloud Run (jobs) qui peuvent √™tre notifi√©s via Cloud Pub/Sub et Cloud workflow pour s'√©x√©cuter d√©s lors  de nouveaux fichiers sont d√©pos√©s dans leurs buckets. Le Cloud Run (Job) les transforme et les stock dans des raw-datasets sur Bigquery. Ensuite un DAG Airflow, sur Composer, ou task Argo sur GKE peuvent √™tre planif√©es selon des horaires ou d√©clench√©s selon des √©venements pour goldeniser la donn√©es et/ou calculer des cas d'usages m√©tiers avec dbt/dataflow sur Bigquery.



### 1. Stockage de donn√©es

Pour des t√©ra/p√©ta-octets de donn√©es, GCP propose **Google Cloud Storage (GCS)** et **BigQuery** comme solutions de stockage principales.
.

- **Polars avec Parquet** : Polars offre un excellent support pour Parquet, qui est un format de stockage colonnaire efficace, id√©al pour les charges de travail analytiques √† grande √©chelle. On peut stocker des fichiers Parquet bruts dans GCS et les charger en m√©moire avec Polars.

### 2. Infrastructure de calcul

#### Option 1 : Google Kubernetes Engine (GKE)
- **GKE** est un service Kubernetes g√©r√© qui peut √™tre utilis√© pour orchestrer des charges de travail conteneuris√©es. Polars peut √™tre emball√© dans un conteneur Docker et ex√©cut√© sur un cluster GKE.
- Avec GKE, On peut faire √©voluer les charges de travail horizontalement en ajoutant plus de pods (conteneurs) ou verticalement en augmentant les ressources des n≈ìuds (machines) individuels.
- **GCSFuse** ou **gcsfs** peuvent √™tre utilis√©s dans vos conteneurs pour acc√©der directement aux donn√©es stock√©es dans GCS. Cette configuration permet de diffuser des donn√©es dans Polars √† partir de GCS sans avoir √† charger l'int√©gralit√© de l'ensemble de donn√©es dans le stockage local.

#### Option 2 : Google Cloud Dataflow
- **Dataflow** est le service de traitement de flux et de lot g√©r√© de GCP, bas√© sur Apache Beam.
- Polars peut √™tre int√©gr√© dans les pipelines Dataflow via des **DoFns** (fonctions distribu√©es) personnalis√©s pour un traitement rapide en m√©moire.
- Les fonctionnalit√©s d'auto-scaling de Dataflow sont id√©ales pour g√©rer de grands ensembles de donn√©es, permettant d'augmenter automatiquement le nombre de travailleurs en fonction de la charge de travail.

#### Option 3 : Google Compute Engine (GCE)
- **GCE** fournit des machines virtuelles (VM) avec des configurations personnalisables de CPU et de m√©moire.
- Polars peut fonctionner sur des instances √† grande m√©moire pour des op√©rations haute performance sur un seul n≈ìud. Pour le traitement distribu√©, On peut combiner GCE avec des outils d'orchestration (par exemple, Dask ou Ray) pour r√©partir les calculs sur plusieurs machines virtuelles. (Managed Instance Groups)

### 3. Orchestration des workflows

#### Option 1 : Cloud Composer (Airflow)
- **Cloud Composer** est la version g√©r√©e par GCP d'Apache Airflow. Il vous permet de cr√©er des graphes acycliques dirig√©s (DAG) pour orchestrer des t√¢ches, telles que la lecture de donn√©es √† partir de GCS, leur traitement avec Polars, et la sauvegarde des r√©sultats dans GCS ou BigQuery.
- On peut planifier les charges de travail de traitement Polars avec Cloud Composer pour les ex√©cuter en mode batch, d√©clench√© par des √©v√©nements comme le t√©l√©chargement de nouvelles donn√©es.

#### Option 2 : Cloud Functions et Cloud Run
- **Cloud Functions** : On peut √©crire du code l√©ger, d√©clench√© par des √©v√©nements, pour lancer des t√¢ches Polars lorsque de nouvelles donn√©es arrivent dans GCS. Ceci est utile pour le traitement en temps r√©el ou quasi temps r√©el.
- **Cloud Run** : D√©ployer Polars dans un conteneur Docker sur Cloud Run, qui √©volue automatiquement en fonction de la demande. Ceci est utile pour des services sans √©tat et √©volutifs (stateless) qui traitent des donn√©es √† la demande.

---

Cette architecture permet √† Polars de traiter efficacement des donn√©es √† l'√©chelle tout en utilisant les services cloud natifs de GCP pour la gestion, l'orchestration, et l'√©volutivit√© des workflows de donn√©es.
